# Install SQLite lib
install.packages("RSQLite")
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(SQLite(), './world_development_indicators/database.sqlite')
dbListTables(conn)
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(SQLite(), '../world_development_indicators/database.sqlite')
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(SQLite(), './world_development_indicators/database.sqlite')
dbListTables(conn)
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(SQLite(), './world_development_indicators/database.sqlite')
dbListTables(conn)
# List all fields in Country table
dbListFields(conn, "Country")
# query db and save results to dataframe
country_names <- dbGetQuery(conn, "SELECT ShortName from Country")
country_names
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(drv=RSQLite::SQLite(),dbname='./world_development_indicators/database.sqlite')
dbListTables(conn)
dbListTables(conn)
# Load lib and get connection
library(RSQLite)
conn <- dbConnect(drv=RSQLite::SQLite(),dbname='./world_development_indicators/database.sqlite')
dbListTables(conn)
options(repr.matrix.max.rows=100, repr.matrix.max.cols=20)
# Libraries
options(warn=-1)
library(ggplot2)
library(dplyr)
library(plotly)
library(hrbrthemes)
library(forecast)
library(xts)
library(Metrics)
library(psych)
library(dygraphs)
library(GGally)
library(tidyverse)
library(tidyquant)
library(cranlogs)
library(corrr)
library(cowplot)
#Import Data into DF
df = read.csv(file='./data/data.csv')
df_genre = read.csv(file='./data/data_by_genres.csv')
df_artist = read.csv(file='./data/data_by_artist.csv')
df_year = read.csv(file='./data/data_by_year.csv')
df_genres2 = read.csv(file='./data/data_w_genres.csv')
# Preview DF
head(df)
head(df_genre)
head(df_artist)
head(df_year)
head(df_genres2)
# Take only unique rows - remove duplicates
df <- df %>% distinct()
# Remove null rows in R
df <- df[rowSums(is.na(df)) == 0,]
# Change year column to a date value
df$year <- as.Date(ISOdate(df$year, 1, 1))
# Get summary of main dataframe
# Data Dimensions
dim(df)
# Column names, column types, preview of data
str(df)
# Statistical summary of every column
summary(df)
# Print all column names
colnames(df)
# Nice visualization of correlations
numerics = df[,!(colnames(df)  %in% c("id","year","artists","name","release_date"))]
tidyverse_static_correlations <- numerics %>% correlate()
print.data.frame(tidyverse_static_correlations)
# Correlation Plot
correlations = cor(numerics)
ggcorr(numerics, method = c("everything", "pearson"))
# Network plot
# To interpret this plot, variables that are more highly correlated appear closer together and are joined by stronger paths. Paths are colored by their
# sign (positive = blue, red = negative).
net_plot <- tidyverse_static_correlations %>%
network_plot(colours = c("indianred2", "black", "skyblue1"),repel=TRUE, legend = TRUE) +
labs(
title = "Network Plot of Correlations of Numeric Features of Spotify Songs"
) +
expand_limits(x = c(-0.75, 0.25), y = c(-0.4, 0.4)) +
theme_tq() +
theme(legend.position = "right")
net_plot
# Get rolling correlations
tidyverse_rolling_corr <- df %>%
# Data wrangling
select(year, energy, loudness) %>%
# Mutation
tq_mutate_xy(
x          = energy,
y          = loudness,
mutate_fun = runCor,
# runCor args
n          = 30,
use        = "pairwise.complete.obs",
# tq_mutate args
col_rename = "rolling_corr"
)
tidyverse_rolling_corr
#Time-Series Analysis
#duration_ts <- ts(df_year$duration_ms,start=df_year$year)
colnames(df_year)
subset_year <- df_year[,!(colnames(df_year)  %in% c("key", "mode", "duration_ms"))]
dygraph(subset_year, main = "Song Features Over Time") %>%
dySeries("tempo", axis = 'y2', label='Tempo') %>%
dySeries("popularity", axis = 'y2', label='Popularity') %>%
dySeries("loudness", axis = 'y2', label='loudness') %>%
dyCSS("legend.css")
